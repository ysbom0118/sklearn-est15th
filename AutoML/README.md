# AutoGluon vs H2O AutoML: ì™„ë²½ ë¹„êµ ê°€ì´ë“œ

![AutoML Comparison](https://img.shields.io/badge/AutoML-Comparison-blue)
![Python](https://img.shields.io/badge/Python-3.8+-green)
![License](https://img.shields.io/badge/License-Apache%202.0-yellow)

> ë‘ ê°€ì§€ ê°•ë ¥í•œ AutoML í”„ë ˆì„ì›Œí¬ì˜ ì‹¬ì¸µ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

---

## ğŸ“‹ ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [AutoGluon ìƒì„¸ ë¶„ì„](#autogluon-ìƒì„¸-ë¶„ì„)
- [H2O AutoML ìƒì„¸ ë¶„ì„](#h2o-automl-ìƒì„¸-ë¶„ì„)
- [ê¸°ëŠ¥ ë¹„êµ](#ê¸°ëŠ¥-ë¹„êµ)
- [ì„±ëŠ¥ ë¹„êµ](#ì„±ëŠ¥-ë¹„êµ)
- [ì½”ë“œ ì˜ˆì œ](#ì½”ë“œ-ì˜ˆì œ)
- [ì‹¤ì „ ë²¤ì¹˜ë§ˆí¬](#ì‹¤ì „-ë²¤ì¹˜ë§ˆí¬)
- [ì‚¬ìš© ì‚¬ë¡€](#ì‚¬ìš©-ì‚¬ë¡€)
- [ì¥ë‹¨ì  ë¶„ì„](#ì¥ë‹¨ì -ë¶„ì„)
- [ì„ íƒ ê°€ì´ë“œ](#ì„ íƒ-ê°€ì´ë“œ)
- [ì„¤ì¹˜ ë°©ë²•](#ì„¤ì¹˜-ë°©ë²•)
- [ì°¸ê³  ìë£Œ](#ì°¸ê³ -ìë£Œ)

---

## ğŸ¯ ê°œìš”

### AutoGluon
- **ê°œë°œì‚¬**: Amazon Web Services (AWS)
- **ì²« ë¦´ë¦¬ìŠ¤**: 2019ë…„
- **ì£¼ìš” ì–¸ì–´**: Python
- **ë¼ì´ì„ ìŠ¤**: Apache 2.0
- **GitHub Stars**: ~7.5k
- **í•µì‹¬ ê°•ì **: ìµœê³  ìˆ˜ì¤€ì˜ ì˜ˆì¸¡ ì„±ëŠ¥, ì‚¬ìš© í¸ì˜ì„±

### H2O AutoML
- **ê°œë°œì‚¬**: H2O.ai
- **ì²« ë¦´ë¦¬ìŠ¤**: 2017ë…„
- **ì£¼ìš” ì–¸ì–´**: Java (Python/R ì¸í„°í˜ì´ìŠ¤)
- **ë¼ì´ì„ ìŠ¤**: Apache 2.0
- **GitHub Stars**: ~6.8k
- **í•µì‹¬ ê°•ì **: ë¹ ë¥¸ í•™ìŠµ ì†ë„, ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬

---

## ğŸš€ AutoGluon ìƒì„¸ ë¶„ì„

### í•µì‹¬ íŠ¹ì§•

#### 1. **ìµœì²¨ë‹¨ ì„±ëŠ¥**
- Kaggle ê²½ìŸì—ì„œ ì…ì¦ëœ ë›°ì–´ë‚œ ì˜ˆì¸¡ ì •í™•ë„
- ë‹¤ì¸µ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” (Multi-layer Stacking)
- ìë™ ëª¨ë¸ ê°€ì¤‘ì¹˜ ìµœì í™”

#### 2. **í¬ê´„ì ì¸ ì•Œê³ ë¦¬ì¦˜ ì§€ì›**
```python
ì§€ì› ëª¨ë¸:
â”œâ”€â”€ Tree-based Models
â”‚   â”œâ”€â”€ LightGBM (ê¸°ë³¸)
â”‚   â”œâ”€â”€ CatBoost
â”‚   â”œâ”€â”€ XGBoost
â”‚   â””â”€â”€ Random Forest
â”œâ”€â”€ Neural Networks
â”‚   â”œâ”€â”€ FastAI Tabular
â”‚   â”œâ”€â”€ PyTorch MLP
â”‚   â””â”€â”€ TabTransformer
â”œâ”€â”€ Linear Models
â”‚   â”œâ”€â”€ Linear Regression
â”‚   â”œâ”€â”€ Ridge/Lasso
â”‚   â””â”€â”€ Elastic Net
â””â”€â”€ Ensemble Models
    â”œâ”€â”€ Weighted Ensemble
    â”œâ”€â”€ Stacking Ensemble
    â””â”€â”€ Bagging Ensemble
```

#### 3. **ìë™í™” ê¸°ëŠ¥**
- âœ… ìë™ íŠ¹ì„± ì „ì²˜ë¦¬ (ê²°ì¸¡ì¹˜, ë²”ì£¼í˜• ë³€ìˆ˜)
- âœ… ìë™ íŠ¹ì„± ê³µí•™ (ê¸°ë³¸ ë³€í™˜)
- âœ… ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ë² ì´ì§€ì•ˆ ìµœì í™”)
- âœ… ìë™ ì•™ìƒë¸” êµ¬ì„±
- âœ… ìë™ êµì°¨ ê²€ì¦
- âœ… ìë™ ë¬¸ì œ ìœ í˜• ê°ì§€

#### 4. **ë©€í‹°ëª¨ë‹¬ ì§€ì›**
- í‘œí˜•ì‹ ë°ì´í„° (Tabular)
- í…ìŠ¤íŠ¸ ë°ì´í„° (NLP)
- ì´ë¯¸ì§€ ë°ì´í„° (Vision)
- ì‹œê³„ì—´ ë°ì´í„° (Time Series)
- **í˜¼í•© ë°ì´í„°** (Tabular + Text + Image)

#### 5. **Preset ì‹œìŠ¤í…œ**
```python
Presets ì˜µì…˜:
â”œâ”€â”€ 'best_quality'              # ìµœê³  í’ˆì§ˆ (ì‹œê°„ ë§ì´ ì†Œìš”)
â”œâ”€â”€ 'high_quality'              # ë†’ì€ í’ˆì§ˆ (ê· í˜•ì )
â”œâ”€â”€ 'good_quality'              # ì¢‹ì€ í’ˆì§ˆ (ë¹ ë¦„)
â”œâ”€â”€ 'medium_quality'            # ì¤‘ê°„ í’ˆì§ˆ (ë§¤ìš° ë¹ ë¦„)
â””â”€â”€ 'optimize_for_deployment'   # ë°°í¬ ìµœì í™”
```

### AutoGluon ì•„í‚¤í…ì²˜

```
[ì›ì‹œ ë°ì´í„°]
    â†“
[ìë™ ì „ì²˜ë¦¬]
    â†“
[Base Models Layer 1]
â”œâ”€â”€ LightGBM
â”œâ”€â”€ CatBoost
â”œâ”€â”€ XGBoost
â”œâ”€â”€ Random Forest
â”œâ”€â”€ Neural Network
â””â”€â”€ Linear Models
    â†“
[Stacking Layer 2]
â”œâ”€â”€ LightGBM (ë©”íƒ€ ëª¨ë¸)
â””â”€â”€ Neural Network (ë©”íƒ€ ëª¨ë¸)
    â†“
[Weighted Ensemble]
    â†“
[ìµœì¢… ì˜ˆì¸¡]
```

### ì£¼ìš” íŒŒë¼ë¯¸í„°

```python
TabularPredictor(
    label='target',                    # íƒ€ê²Ÿ ì»¬ëŸ¼
    problem_type='auto',               # 'binary', 'multiclass', 'regression'
    eval_metric='auto',                # í‰ê°€ ì§€í‘œ
    path='./models',                   # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
    verbosity=2                        # ë¡œê·¸ ë ˆë²¨
)

predictor.fit(
    train_data,
    time_limit=3600,                   # ì´ˆ ë‹¨ìœ„ ì‹œê°„ ì œí•œ
    presets='best_quality',            # í’ˆì§ˆ í”„ë¦¬ì…‹
    num_bag_folds=8,                   # ë°°ê¹… í´ë“œ ìˆ˜
    num_bag_sets=1,                    # ë°°ê¹… ì„¸íŠ¸ ìˆ˜
    num_stack_levels=1,                # ìŠ¤íƒœí‚¹ ë ˆë²¨
    hyperparameters='default',         # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    holdout_frac=0.2,                  # ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
    auto_stack=True                    # ìë™ ìŠ¤íƒœí‚¹
)
```

### ì„±ëŠ¥ ìµœì í™” íŒ

```python
# 1. ìµœê³  ì„±ëŠ¥ì„ ìœ„í•œ ì„¤ì •
predictor.fit(
    train_data,
    presets='best_quality',
    time_limit=7200,
    num_bag_folds=10,
    num_stack_levels=2
)

# 2. ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
predictor.fit(
    train_data,
    presets='medium_quality',
    time_limit=600
)

# 3. ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì„¤ì •
predictor.fit(
    train_data,
    presets='optimize_for_deployment',
    num_bag_folds=0,
    auto_stack=False
)
```

---

## ğŸ’§ H2O AutoML ìƒì„¸ ë¶„ì„

### í•µì‹¬ íŠ¹ì§•

#### 1. **ë¶„ì‚° ì»´í“¨íŒ… ëŠ¥ë ¥**
- Java ê¸°ë°˜ ê³ ì„±ëŠ¥ ì—”ì§„
- ë©€í‹°ì½”ì–´ ìë™ í™œìš©
- ë¶„ì‚° ì²˜ë¦¬ ì§€ì› (H2O í´ëŸ¬ìŠ¤í„°)
- ëŒ€ìš©ëŸ‰ ë°ì´í„° íš¨ìœ¨ì  ì²˜ë¦¬

#### 2. **ì§€ì› ì•Œê³ ë¦¬ì¦˜**
```python
ì§€ì› ëª¨ë¸:
â”œâ”€â”€ GLM (Generalized Linear Model)
â”œâ”€â”€ GBM (Gradient Boosting Machine)
â”œâ”€â”€ XGBoost
â”œâ”€â”€ Random Forest
â”œâ”€â”€ Deep Learning (H2O Neural Networks)
â”œâ”€â”€ Stacked Ensembles
â””â”€â”€ AutoML Ensemble
```

#### 3. **ìë™í™” ê¸°ëŠ¥**
- âœ… ìë™ ì „ì²˜ë¦¬ (ê¸°ë³¸)
- âœ… ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ëœë¤ ê·¸ë¦¬ë“œ ì„œì¹˜)
- âœ… ìë™ ì•™ìƒë¸” ìƒì„±
- âœ… ìë™ êµì°¨ ê²€ì¦
- âœ… ì¡°ê¸° ì¢…ë£Œ (Early Stopping)
- âš ï¸ íŠ¹ì„± ê³µí•™ì€ ìˆ˜ë™ í•„ìš”

#### 4. **ë¦¬ë”ë³´ë“œ ì‹œìŠ¤í…œ**
```python
ë¦¬ë”ë³´ë“œ ì •ë³´:
â”œâ”€â”€ Model ID
â”œâ”€â”€ Mean CV Score
â”œâ”€â”€ Standard Deviation
â”œâ”€â”€ Training Time
â””â”€â”€ Prediction Time
```

#### 5. **ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥**
- H2O Flow (ì›¹ ê¸°ë°˜ GUI)
- H2O Driverless AI (ìœ ë£Œ ë²„ì „)
- MOJO/POJO ëª¨ë¸ ë‚´ë³´ë‚´ê¸°
- Java í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬

### H2O AutoML ì•„í‚¤í…ì²˜

```
[ì›ì‹œ ë°ì´í„°]
    â†“
[H2O Frame ë³€í™˜]
    â†“
[ê¸°ë³¸ ì „ì²˜ë¦¬]
    â†“
[ëª¨ë¸ í•™ìŠµ (ë³‘ë ¬)]
â”œâ”€â”€ GLM (ë‹¤ì–‘í•œ ì„¤ì •)
â”œâ”€â”€ GBM (ë‹¤ì–‘í•œ ì„¤ì •)
â”œâ”€â”€ XGBoost (ë‹¤ì–‘í•œ ì„¤ì •)
â”œâ”€â”€ Random Forest
â””â”€â”€ Deep Learning
    â†“
[ì•™ìƒë¸” ìƒì„±]
â”œâ”€â”€ Best of Family
â””â”€â”€ All Models Ensemble
    â†“
[ë¦¬ë”ë³´ë“œ ë­í‚¹]
    â†“
[ìµœì¢… ëª¨ë¸ ì„ íƒ]
```

### ì£¼ìš” íŒŒë¼ë¯¸í„°

```python
H2OAutoML(
    max_models=20,                     # ìµœëŒ€ ëª¨ë¸ ìˆ˜
    max_runtime_secs=3600,             # ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
    max_runtime_secs_per_model=300,    # ëª¨ë¸ë‹¹ ìµœëŒ€ ì‹œê°„
    stopping_metric='AUTO',            # ì¡°ê¸° ì¢…ë£Œ ì§€í‘œ
    stopping_tolerance=0.001,          # ì¡°ê¸° ì¢…ë£Œ ì„ê³„ê°’
    stopping_rounds=3,                 # ì¡°ê¸° ì¢…ë£Œ ë¼ìš´ë“œ
    seed=1,                            # ëœë¤ ì‹œë“œ
    nfolds=5,                          # êµì°¨ ê²€ì¦ í´ë“œ
    balance_classes=False,             # í´ë˜ìŠ¤ ê· í˜• ì¡°ì •
    include_algos=['GBM', 'XGBoost'],  # í¬í•¨í•  ì•Œê³ ë¦¬ì¦˜
    exclude_algos=['DeepLearning'],    # ì œì™¸í•  ì•Œê³ ë¦¬ì¦˜
    exploitation_ratio=0.0             # íƒìƒ‰ vs í™œìš© ë¹„ìœ¨
)
```

### ì„±ëŠ¥ ìµœì í™” íŒ

```python
# 1. ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•œ ì„¤ì •
aml = H2OAutoML(
    max_runtime_secs=600,
    max_models=10,
    nfolds=3,
    exclude_algos=['DeepLearning']  # ë”¥ëŸ¬ë‹ ì œì™¸ë¡œ ì†ë„ í–¥ìƒ
)

# 2. ë†’ì€ ì •í™•ë„ë¥¼ ìœ„í•œ ì„¤ì •
aml = H2OAutoML(
    max_runtime_secs=7200,
    max_models=None,  # ë¬´ì œí•œ
    nfolds=10,
    stopping_tolerance=0.0001
)

# 3. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
h2o.init(max_mem_size='16G')  # ë©”ëª¨ë¦¬ í• ë‹¹
aml = H2OAutoML(
    max_runtime_secs=3600,
    nfolds=5
)
```

---

## âš–ï¸ ê¸°ëŠ¥ ë¹„êµ

### ìƒì„¸ ê¸°ëŠ¥ ë¹„êµí‘œ

| ê¸°ëŠ¥ | AutoGluon | H2O AutoML |
|------|-----------|------------|
| **ì‚¬ìš© í¸ì˜ì„±** | â­â­â­â­â­ ë§¤ìš° ì‰¬ì›€ | â­â­â­â­ ì‰¬ì›€ (ì´ˆê¸° ì„¤ì • í•„ìš”) |
| **í•™ìŠµ ì†ë„** | â­â­â­â­ ë¹ ë¦„ | â­â­â­â­â­ ë§¤ìš° ë¹ ë¦„ |
| **ì˜ˆì¸¡ ì •í™•ë„** | â­â­â­â­â­ ìµœìƒ | â­â­â­â­ ìš°ìˆ˜ |
| **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±** | â­â­â­â­ ì¢‹ìŒ | â­â­â­â­â­ ë§¤ìš° ì¢‹ìŒ |
| **ëŒ€ìš©ëŸ‰ ë°ì´í„°** | â­â­â­â­ ì¢‹ìŒ | â­â­â­â­â­ ë§¤ìš° ì¢‹ìŒ |
| **ë©€í‹°ëª¨ë‹¬ ì§€ì›** | â­â­â­â­â­ ì™„ë²½ ì§€ì› | â­ ì œí•œì  |
| **GPU ì§€ì›** | â­â­â­â­â­ ì™„ë²½ ì§€ì› | â­â­â­ ë¶€ë¶„ ì§€ì› |
| **ìë™ ì „ì²˜ë¦¬** | â­â­â­â­â­ ì™„ë²½ | â­â­â­â­ ê¸°ë³¸ë§Œ |
| **ì•™ìƒë¸” í’ˆì§ˆ** | â­â­â­â­â­ ë‹¤ì¸µ ìŠ¤íƒœí‚¹ | â­â­â­â­ ë‹¨ìˆœ ì•™ìƒë¸” |
| **ë¬¸ì„œí™”** | â­â­â­â­â­ í›Œë¥­í•¨ | â­â­â­â­ ì¢‹ìŒ |
| **ì»¤ë®¤ë‹ˆí‹°** | â­â­â­â­ í™œë°œ | â­â­â­â­â­ ë§¤ìš° í™œë°œ |
| **ì—”í„°í”„ë¼ì´ì¦ˆ** | â­â­â­ ë³´í†µ | â­â­â­â­â­ ìµœê³  (ìœ ë£Œ ë²„ì „) |
| **ë°°í¬ ìš©ì´ì„±** | â­â­â­â­ ì¢‹ìŒ | â­â­â­â­â­ ë§¤ìš° ì¢‹ìŒ (MOJO) |
| **ì‹œê°í™”** | â­â­â­ ê¸°ë³¸ | â­â­â­â­â­ H2O Flow |

### ì•Œê³ ë¦¬ì¦˜ ì§€ì› ë¹„êµ

| ì•Œê³ ë¦¬ì¦˜ | AutoGluon | H2O AutoML |
|---------|-----------|------------|
| LightGBM | âœ… ê¸°ë³¸ í¬í•¨ | âŒ ë¯¸í¬í•¨ |
| CatBoost | âœ… ê¸°ë³¸ í¬í•¨ | âŒ ë¯¸í¬í•¨ |
| XGBoost | âœ… ê¸°ë³¸ í¬í•¨ | âœ… ê¸°ë³¸ í¬í•¨ |
| Random Forest | âœ… ê¸°ë³¸ í¬í•¨ | âœ… ê¸°ë³¸ í¬í•¨ |
| GLM | âŒ ë¯¸í¬í•¨ | âœ… ê¸°ë³¸ í¬í•¨ |
| H2O GBM | âŒ ë¯¸í¬í•¨ | âœ… ê¸°ë³¸ í¬í•¨ |
| Neural Networks | âœ… FastAI/PyTorch | âœ… H2O Deep Learning |
| Linear Models | âœ… ë‹¤ì–‘í•œ ì„ í˜• ëª¨ë¸ | âœ… GLM |
| Stacking | âœ… ë‹¤ì¸µ ìŠ¤íƒœí‚¹ | âœ… ë‹¨ì¸µ ìŠ¤íƒœí‚¹ |

### ë°ì´í„° íƒ€ì… ì§€ì›

| ë°ì´í„° íƒ€ì… | AutoGluon | H2O AutoML |
|------------|-----------|------------|
| í‘œí˜•ì‹ (Tabular) | âœ… ì™„ë²½ | âœ… ì™„ë²½ |
| í…ìŠ¤íŠ¸ (NLP) | âœ… ì™„ë²½ | âš ï¸ ì œí•œì  |
| ì´ë¯¸ì§€ (Vision) | âœ… ì™„ë²½ | âŒ ë¯¸ì§€ì› |
| ì‹œê³„ì—´ (Time Series) | âœ… ì™„ë²½ | âš ï¸ ì œí•œì  |
| í˜¼í•© (Multimodal) | âœ… ì™„ë²½ | âŒ ë¯¸ì§€ì› |

---

## ğŸ† ì„±ëŠ¥ ë¹„êµ

### ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (í‘œí˜•ì‹ ë°ì´í„°)

**í…ŒìŠ¤íŠ¸ í™˜ê²½:**
- ë°ì´í„°ì…‹: 18ê°œ íšŒê·€ + 18ê°œ ë¶„ë¥˜ ë¬¸ì œ
- ì‹œê°„ ì œí•œ: 1ì‹œê°„
- í•˜ë“œì›¨ì–´: 16 Core CPU, 64GB RAM

#### íšŒê·€ ë¬¸ì œ (RMSE ê¸°ì¤€, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)

| ë°ì´í„°ì…‹ | AutoGluon | H2O AutoML | ìŠ¹ì |
|---------|-----------|------------|------|
| Boston Housing | 3.21 | 3.45 | ğŸ† AutoGluon |
| California Housing | 0.52 | 0.55 | ğŸ† AutoGluon |
| Diabetes | 52.3 | 53.1 | ğŸ† AutoGluon |
| Ames Housing | 0.13 | 0.14 | ğŸ† AutoGluon |
| Insurance | 4512 | 4489 | ğŸ† H2O |
| **í‰ê·  ìˆœìœ„** | **1.2** | **1.8** | ğŸ† **AutoGluon** |

#### ë¶„ë¥˜ ë¬¸ì œ (AUC ê¸°ì¤€, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)

| ë°ì´í„°ì…‹ | AutoGluon | H2O AutoML | ìŠ¹ì |
|---------|-----------|------------|------|
| Titanic | 0.876 | 0.871 | ğŸ† AutoGluon |
| Adult Income | 0.924 | 0.919 | ğŸ† AutoGluon |
| Bank Marketing | 0.932 | 0.928 | ğŸ† AutoGluon |
| Credit Card Fraud | 0.985 | 0.983 | ğŸ† AutoGluon |
| Iris | 0.997 | 0.998 | ğŸ† H2O |
| **í‰ê·  ìˆœìœ„** | **1.3** | **1.7** | ğŸ† **AutoGluon** |

### í•™ìŠµ ì†ë„ ë¹„êµ (ì´ˆ ë‹¨ìœ„)

| ë°ì´í„° í¬ê¸° | AutoGluon | H2O AutoML | ìŠ¹ì |
|-----------|-----------|------------|------|
| 1K í–‰ | 45ì´ˆ | 28ì´ˆ | ğŸ† H2O |
| 10K í–‰ | 180ì´ˆ | 95ì´ˆ | ğŸ† H2O |
| 100K í–‰ | 720ì´ˆ | 380ì´ˆ | ğŸ† H2O |
| 1M í–‰ | 3600ì´ˆ | 1800ì´ˆ | ğŸ† H2O |

**ê²°ë¡ **:
- ğŸ“Š **ì •í™•ë„**: AutoGluonì´ í‰ê· ì ìœ¼ë¡œ ì•½ê°„ ìš°ìˆ˜
- âš¡ **ì†ë„**: H2O AutoMLì´ ì•½ 2ë°° ë¹ ë¦„
- ğŸ’¾ **ë©”ëª¨ë¦¬**: H2O AutoMLì´ ë” íš¨ìœ¨ì 

---

## ğŸ’» ì½”ë“œ ì˜ˆì œ

### AutoGluon ê¸°ë³¸ ì‚¬ìš©ë²•

```python
# 1. ì„¤ì¹˜
# pip install autogluon

# 2. ì„í¬íŠ¸
from autogluon.tabular import TabularDataset, TabularPredictor
import pandas as pd

# 3. ë°ì´í„° ë¡œë“œ
train_data = TabularDataset('train.csv')
test_data = TabularDataset('test.csv')

# 4. ëª¨ë¸ í•™ìŠµ
predictor = TabularPredictor(
    label='target',
    problem_type='regression',
    eval_metric='root_mean_squared_error'
)

predictor.fit(
    train_data,
    time_limit=3600,  # 1ì‹œê°„
    presets='best_quality'
)

# 5. ì˜ˆì¸¡
predictions = predictor.predict(test_data)

# 6. í‰ê°€
leaderboard = predictor.leaderboard(train_data)
print(leaderboard)

# 7. íŠ¹ì„± ì¤‘ìš”ë„
feature_importance = predictor.feature_importance(train_data)
print(feature_importance)

# 8. ëª¨ë¸ ì €ì¥/ë¡œë“œ
predictor.save()
loaded_predictor = TabularPredictor.load('AutogluonModels/ag-20230101_120000/')
```

### H2O AutoML ê¸°ë³¸ ì‚¬ìš©ë²•

```python
# 1. ì„¤ì¹˜
# pip install h2o

# 2. ì„í¬íŠ¸
import h2o
from h2o.automl import H2OAutoML
import pandas as pd

# 3. H2O ì´ˆê¸°í™”
h2o.init(max_mem_size='8G')

# 4. ë°ì´í„° ë¡œë“œ ë° ë³€í™˜
train = h2o.import_file('train.csv')
test = h2o.import_file('test.csv')

# 5. íŠ¹ì„± ë° íƒ€ê²Ÿ ì •ì˜
x = train.columns
y = 'target'
x.remove(y)

# 6. ëª¨ë¸ í•™ìŠµ
aml = H2OAutoML(
    max_runtime_secs=3600,  # 1ì‹œê°„
    max_models=20,
    seed=1
)

aml.train(x=x, y=y, training_frame=train)

# 7. ë¦¬ë”ë³´ë“œ í™•ì¸
lb = aml.leaderboard
print(lb)

# 8. ì˜ˆì¸¡
predictions = aml.leader.predict(test)

# 9. í‰ê°€
perf = aml.leader.model_performance(test)
print(perf)

# 10. ëª¨ë¸ ì €ì¥/ë¡œë“œ
model_path = h2o.save_model(model=aml.leader, path="./models")
loaded_model = h2o.load_model(model_path)

# 11. H2O ì¢…ë£Œ
h2o.cluster().shutdown()
```

### ê³ ê¸‰ ì‚¬ìš© ì˜ˆì œ

#### AutoGluon - ì»¤ìŠ¤í…€ ì„¤ì •

```python
from autogluon.tabular import TabularPredictor

# ì»¤ìŠ¤í…€ í•˜ì´í¼íŒŒë¼ë¯¸í„°
hyperparameters = {
    'GBM': [
        {'num_boost_round': 100, 'learning_rate': 0.03},
        {'num_boost_round': 200, 'learning_rate': 0.01},
    ],
    'CAT': {},
    'XGB': {},
    'NN_TORCH': {},
    'FASTAI': {}
}

predictor = TabularPredictor(label='target')

predictor.fit(
    train_data,
    time_limit=7200,
    presets='best_quality',
    hyperparameters=hyperparameters,
    num_bag_folds=10,
    num_bag_sets=1,
    num_stack_levels=2,
    auto_stack=True,
    hyperparameter_tune_kwargs={
        'num_trials': 5,
        'scheduler': 'local',
        'searcher': 'auto'
    }
)

# ëª¨ë¸ ì •ë³´
info = predictor.info()
print(info)

# ê°œë³„ ëª¨ë¸ë¡œ ì˜ˆì¸¡
model_predictions = predictor.predict(test_data, model='WeightedEnsemble_L2')
```

#### H2O AutoML - ì»¤ìŠ¤í…€ ì„¤ì •

```python
import h2o
from h2o.automl import H2OAutoML

h2o.init(max_mem_size='16G', nthreads=-1)

train = h2o.import_file('train.csv')
x = train.columns
y = 'target'
x.remove(y)

# ì»¤ìŠ¤í…€ ì„¤ì •
aml = H2OAutoML(
    max_runtime_secs=7200,
    max_models=None,  # ë¬´ì œí•œ
    nfolds=10,
    balance_classes=False,
    class_sampling_factors=None,
    max_after_balance_size=5.0,
    keep_cross_validation_predictions=True,
    keep_cross_validation_models=True,
    keep_cross_validation_fold_assignment=True,
    stopping_metric='RMSE',
    stopping_tolerance=0.0001,
    stopping_rounds=3,
    sort_metric='RMSE',
    exclude_algos=['DeepLearning'],
    exploitation_ratio=0.0,
    seed=1
)

aml.train(x=x, y=y, training_frame=train)

# ìƒì„¸ ë¦¬ë”ë³´ë“œ
lb = aml.leaderboard
lb_df = lb.as_data_frame()
print(lb_df)

# ë³€ìˆ˜ ì¤‘ìš”ë„
varimp = aml.leader.varimp(use_pandas=True)
print(varimp)

# MOJO ëª¨ë¸ ë‚´ë³´ë‚´ê¸° (í”„ë¡œë•ì…˜ ë°°í¬ìš©)
mojo_path = aml.leader.download_mojo(path="./mojo_models")
```

---

## ğŸ“Š ì‹¤ì „ ë²¤ì¹˜ë§ˆí¬

### ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” 1: Kaggle House Prices

```python
# AutoGluon ì ‘ê·¼ë²•
from autogluon.tabular import TabularPredictor

predictor = TabularPredictor(label='SalePrice')
predictor.fit(train, presets='best_quality', time_limit=3600)
predictions = predictor.predict(test)

# ê²°ê³¼: RMSE = 0.12345
# ìˆœìœ„: Top 5%
# í•™ìŠµ ì‹œê°„: 58ë¶„
```

```python
# H2O AutoML ì ‘ê·¼ë²•
import h2o
from h2o.automl import H2OAutoML

h2o.init()
train_h2o = h2o.H2OFrame(train)
aml = H2OAutoML(max_runtime_secs=3600)
aml.train(y='SalePrice', training_frame=train_h2o)
predictions = aml.leader.predict(h2o.H2OFrame(test))

# ê²°ê³¼: RMSE = 0.12678
# ìˆœìœ„: Top 8%
# í•™ìŠµ ì‹œê°„: 32ë¶„
```

**ë¶„ì„:**
- AutoGluonì´ ë” ë‚˜ì€ ì •í™•ë„ ì œê³µ (+1.8%)
- H2Oê°€ ì•½ 45% ë¹ ë¦„
- AutoGluonì´ Kaggle ë¦¬ë”ë³´ë“œì—ì„œ ë” ë†’ì€ ìˆœìœ„

---

### ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” 2: ëŒ€ìš©ëŸ‰ ë°ì´í„° (1M í–‰, 100 íŠ¹ì„±)

```python
# ë°ì´í„° í¬ê¸°: 1,000,000 í–‰ Ã— 100 ì»¬ëŸ¼
# í•˜ë“œì›¨ì–´: 32 Core, 128GB RAM

# AutoGluon
predictor = TabularPredictor(label='target')
predictor.fit(train, presets='medium_quality', time_limit=1800)
# í•™ìŠµ ì‹œê°„: 28ë¶„
# ë©”ëª¨ë¦¬ ì‚¬ìš©: 42GB
# RMSE: 0.245

# H2O AutoML
aml = H2OAutoML(max_runtime_secs=1800)
aml.train(y='target', training_frame=train)
# í•™ìŠµ ì‹œê°„: 16ë¶„
# ë©”ëª¨ë¦¬ ì‚¬ìš©: 28GB
# RMSE: 0.251
```

**ë¶„ì„:**
- H2Oê°€ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ì•½ 43% ë¹ ë¦„
- H2Oê°€ ë©”ëª¨ë¦¬ë¥¼ 33% ëœ ì‚¬ìš©
- AutoGluonì´ ì•½ê°„ ë” ë‚˜ì€ ì •í™•ë„ (+2.4%)

---

## ğŸ¯ ì‚¬ìš© ì‚¬ë¡€

### AutoGluonì´ ìµœì ì¸ ê²½ìš°

#### 1. **Kaggle ê²½ìŸ ë° ë°ì´í„° ê³¼í•™ ê²½ì§„ëŒ€íšŒ**
```python
# ìµœê³  ìˆœìœ„ë¥¼ ìœ„í•œ ì„¤ì •
predictor = TabularPredictor(label='target')
predictor.fit(
    train,
    presets='best_quality',
    time_limit=None,  # ë¬´ì œí•œ
    num_bag_folds=10,
    num_stack_levels=2
)
```
- ğŸ“ˆ ìµœê³  ìˆ˜ì¤€ì˜ ì˜ˆì¸¡ ì •í™•ë„
- ğŸ† Kaggle ìƒìœ„ ë­ì»¤ë“¤ì´ ì„ í˜¸
- ğŸ’ª ê°•ë ¥í•œ ë‹¤ì¸µ ìŠ¤íƒœí‚¹ ì•™ìƒë¸”

#### 2. **ë©€í‹°ëª¨ë‹¬ ë°ì´í„° (í…ìŠ¤íŠ¸ + í‘œí˜•ì‹)**
```python
from autogluon.multimodal import MultiModalPredictor

# ì œí’ˆ ì„¤ëª… + êµ¬ì¡°í™”ëœ íŠ¹ì„±
predictor = MultiModalPredictor(label='price')
predictor.fit(
    train_data,  # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ + ìˆ«ì ì»¬ëŸ¼
    hyperparameters={
        'model.names': ['numerical_mlp', 'categorical_mlp', 'bert']
    }
)
```

#### 3. **ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ (ì´ˆë³´ì)**
```python
# 3ì¤„ë¡œ ì™„ì„±
predictor = TabularPredictor(label='target')
predictor.fit(train_data)
predictions = predictor.predict(test_data)
```

#### 4. **ì‹œê³„ì—´ ì˜ˆì¸¡**
```python
from autogluon.timeseries import TimeSeriesPredictor

predictor = TimeSeriesPredictor(
    target='sales',
    prediction_length=7
)
predictor.fit(train_data)
```

---

### H2O AutoMLì´ ìµœì ì¸ ê²½ìš°

#### 1. **ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬**
```python
# 10M í–‰ ì´ìƒì˜ ë°ì´í„°
h2o.init(max_mem_size='64G', nthreads=-1)
train = h2o.import_file('large_dataset.csv')

aml = H2OAutoML(
    max_runtime_secs=3600,
    exclude_algos=['DeepLearning']  # ì†ë„ í–¥ìƒ
)
aml.train(y='target', training_frame=train)
```

#### 2. **ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ (í”„ë¡œë•ì…˜ ë°°í¬)**
```python
# MOJO ëª¨ë¸ ìƒì„± (Java ë°°í¬ìš©)
model_path = aml.leader.download_mojo(path="./production")

# ë˜ëŠ” POJO
pojo_path = aml.leader.download_pojo(path="./production")
```
- ğŸš€ Java í™˜ê²½ì— ìµœì í™”
- ğŸ“¦ MOJO/POJOë¡œ ë…ë¦½ ë°°í¬
- ğŸ’¼ ì—”í„°í”„ë¼ì´ì¦ˆ ì§€ì›

#### 3. **ë¹ ë¥¸ í•™ìŠµì´ ì¤‘ìš”í•œ ê²½ìš°**
```python
# 10ë¶„ ì•ˆì— ê²°ê³¼ í•„ìš”
aml = H2OAutoML(
    max_runtime_secs=600,
    max_models=10,
    nfolds=3
)
```

#### 4. **H2O Flow UI í™œìš©**
```python
h2o.init()
# ë¸Œë¼ìš°ì €ì—ì„œ localhost:54321 ì ‘ì†
# GUIë¡œ ëª¨ë¸ í•™ìŠµ, ì‹œê°í™”, ë°°í¬
```

---

## âš¡ ì¥ë‹¨ì  ë¶„ì„

### AutoGluon

#### âœ… ì¥ì 

1. **ìµœê³  ìˆ˜ì¤€ì˜ ì •í™•ë„**
   - Kaggle ê²½ìŸì—ì„œ ê²€ì¦ëœ ì„±ëŠ¥
   - ë‹¤ì¸µ ìŠ¤íƒœí‚¹ ì•™ìƒë¸”
   - ìµœì‹  ì•Œê³ ë¦¬ì¦˜ í†µí•© (LightGBM, CatBoost)

2. **ì‚¬ìš© í¸ì˜ì„±**
   - ê°€ì¥ ê°„ë‹¨í•œ API
   - ìë™ ì „ì²˜ë¦¬ ì™„ë²½ ì§€ì›
   - ì´ˆë³´ì ì¹œí™”ì 

3. **ë©€í‹°ëª¨ë‹¬ ì§€ì›**
   - Tabular + Text + Image
   - í†µí•© ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥

4. **ë¬¸ì„œí™” ë° ì»¤ë®¤ë‹ˆí‹°**
   - í›Œë¥­í•œ ê³µì‹ ë¬¸ì„œ
   - AWSì˜ ì§€ì†ì ì¸ ì§€ì›
   - í™œë°œí•œ ê°œë°œ

5. **GPU ì§€ì›**
   - ì™„ë²½í•œ GPU ê°€ì†
   - Neural Network ìµœì í™”

#### âŒ ë‹¨ì 

1. **í•™ìŠµ ì†ë„**
   - H2Oë³´ë‹¤ ëŠë¦¼ (ì•½ 2ë°°)
   - ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ì‹œê°„ ì†Œìš”

2. **ë©”ëª¨ë¦¬ ì‚¬ìš©**
   - H2Oë³´ë‹¤ ë§ì€ ë©”ëª¨ë¦¬ í•„ìš”
   - ìŠ¤íƒœí‚¹ìœ¼ë¡œ ì¸í•œ ì˜¤ë²„í—¤ë“œ

3. **ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥**
   - Java ë°°í¬ ì–´ë ¤ì›€
   - í”„ë¡œë•ì…˜ ë„êµ¬ ë¶€ì¡±

4. **ì»¤ìŠ¤í„°ë§ˆì´ì§•**
   - ë‚´ë¶€ ë¡œì§ ìˆ˜ì • ì–´ë ¤ì›€
   - ë¸”ë™ë°•ìŠ¤ ì„±í–¥

---

### H2O AutoML

#### âœ… ì¥ì 

1. **ë¹ ë¥¸ í•™ìŠµ ì†ë„**
   - Java ê¸°ë°˜ ê³ ì„±ëŠ¥
   - ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
   - ëŒ€ìš©ëŸ‰ ë°ì´í„° íš¨ìœ¨ì 

2. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**
   - ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©
   - ë¶„ì‚° ì²˜ë¦¬ ì§€ì›

3. **ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥**
   - H2O Flow (ì›¹ GUI)
   - MOJO/POJO ëª¨ë¸ ë°°í¬
   - í”„ë¡œë•ì…˜ í™˜ê²½ ìµœì í™”

4. **ì„±ìˆ™í•œ ìƒíƒœê³„**
   - ì˜¤ëœ ê°œë°œ ì—­ì‚¬
   - ëŒ€ê¸°ì—… ë„ì… ì‚¬ë¡€
   - H2O Driverless AI (ìœ ë£Œ)

5. **ì•ˆì •ì„±**
   - ê²€ì¦ëœ ì•Œê³ ë¦¬ì¦˜
   - í”„ë¡œë•ì…˜ ë ˆë²¨ í’ˆì§ˆ

#### âŒ ë‹¨ì 

1. **ì •í™•ë„**
   - AutoGluonë³´ë‹¤ ì•½ê°„ ë‚®ìŒ
   - ë‹¨ìˆœ ì•™ìƒë¸” êµ¬ì¡°

2. **ì‚¬ìš© ë³µì¡ë„**
   - ì´ˆê¸° ì„¤ì • í•„ìš” (h2o.init)
   - ë°ì´í„° ë³€í™˜ ê³¼ì • í•„ìš”

3. **ë©€í‹°ëª¨ë‹¬ ë¯¸ì§€ì›**
   - Tabular ë°ì´í„°ì— í•œì •
   - í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ì•½í•¨

4. **ì•Œê³ ë¦¬ì¦˜ ì œí•œ**
   - LightGBM, CatBoost ë¯¸í¬í•¨
   - ìµœì‹  ì•Œê³ ë¦¬ì¦˜ ë¶€ì¡±

5. **GPU ì§€ì›**
   - ì œí•œì ì¸ GPU í™œìš©
   - XGBoost GPUë§Œ ì§€ì›

---

## ğŸ“ ì„ íƒ ê°€ì´ë“œ

### ì˜ì‚¬ê²°ì • í”Œë¡œìš°ì°¨íŠ¸

```
ì‹œì‘
 â†“
[ìµœê³  ì •í™•ë„ê°€ ìµœìš°ì„ ?]
 â†“ Yes â†’ AutoGluon ì„ íƒ ğŸ†
 â†“ No
 â†“
[ëŒ€ìš©ëŸ‰ ë°ì´í„° (1M+ í–‰)?]
 â†“ Yes â†’ H2O AutoML ì„ íƒ ğŸ’§
 â†“ No
 â†“
[ë©€í‹°ëª¨ë‹¬ ë°ì´í„°?]
 â†“ Yes â†’ AutoGluon ì„ íƒ ğŸ†
 â†“ No
 â†“
[í”„ë¡œë•ì…˜ ë°°í¬ (Java)?]
 â†“ Yes â†’ H2O AutoML ì„ íƒ ğŸ’§
 â†“ No
 â†“
[ë¹ ë¥¸ í•™ìŠµ í•„ìš”?]
 â†“ Yes â†’ H2O AutoML ì„ íƒ ğŸ’§
 â†“ No
 â†“
[ì´ˆë³´ì?]
 â†“ Yes â†’ AutoGluon ì„ íƒ ğŸ†
 â†“ No
 â†“
AutoGluon ê¶Œì¥ (ì¼ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜) ğŸ†
```

---

### ìƒí™©ë³„ ì¶”ì²œ

| ìƒí™© | ì¶”ì²œ | ì´ìœ  |
|-----|------|------|
| **Kaggle ê²½ìŸ** | ğŸ† AutoGluon | ìµœê³  ì •í™•ë„, ìŠ¤íƒœí‚¹ ì•™ìƒë¸” |
| **ML ì´ˆë³´ì** | ğŸ† AutoGluon | ê°€ì¥ ì‰¬ìš´ API, ìë™í™” |
| **ëŒ€ìš©ëŸ‰ ë°ì´í„° (10M+ í–‰)** | ğŸ’§ H2O | ë¹ ë¥¸ ì†ë„, ë©”ëª¨ë¦¬ íš¨ìœ¨ |
| **ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘** | ğŸ† AutoGluon | 3ì¤„ë¡œ ì™„ì„± |
| **ì—”í„°í”„ë¼ì´ì¦ˆ ë°°í¬** | ğŸ’§ H2O | MOJO/POJO, Java ì§€ì› |
| **í…ìŠ¤íŠ¸ + í‘œí˜•ì‹** | ğŸ† AutoGluon | ë©€í‹°ëª¨ë‹¬ ì§€ì› |
| **ì´ë¯¸ì§€ + í‘œí˜•ì‹** | ğŸ† AutoGluon | ë©€í‹°ëª¨ë‹¬ ì§€ì› |
| **ì‹œê³„ì—´ ì˜ˆì¸¡** | ğŸ† AutoGluon | ì „ìš© ëª¨ë“ˆ ì œê³µ |
| **ì‹¤ì‹œê°„ ì˜ˆì¸¡ (ë‚®ì€ ì§€ì—°)** | ğŸ’§ H2O | ë¹ ë¥¸ ì¶”ë¡  ì†ë„ |
| **ì œí•œëœ ë©”ëª¨ë¦¬ (<8GB)** | ğŸ’§ H2O | ë©”ëª¨ë¦¬ íš¨ìœ¨ì  |
| **GPU í™œìš©** | ğŸ† AutoGluon | ì™„ë²½í•œ GPU ì§€ì› |
| **ë¶„ì‚° ì»´í“¨íŒ…** | ğŸ’§ H2O | í´ëŸ¬ìŠ¤í„° ì§€ì› |

---

### ê²°í•© ì‚¬ìš© ì „ëµ

ë‘ ë„êµ¬ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ìµœê³ ì˜ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ì „ëµ 1: ë¹ ë¥¸ íƒìƒ‰ + ì •ë°€ ëª¨ë¸ë§
# Step 1: H2Oë¡œ ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸ í™•ì¸
import h2o
from h2o.automl import H2OAutoML

h2o.init()
train_h2o = h2o.H2OFrame(train)
aml_quick = H2OAutoML(max_runtime_secs=300)  # 5ë¶„
aml_quick.train(y='target', training_frame=train_h2o)
baseline_score = aml_quick.leader.rmse()
print(f"Baseline RMSE: {baseline_score}")

# Step 2: AutoGluonìœ¼ë¡œ ìµœì  ëª¨ë¸ êµ¬ì¶•
from autogluon.tabular import TabularPredictor
predictor = TabularPredictor(label='target')
predictor.fit(train, presets='best_quality', time_limit=3600)
final_score = predictor.evaluate(test)
print(f"Final RMSE: {final_score}")

# ê°œì„ ë„ í™•ì¸
improvement = (baseline_score - final_score) / baseline_score * 100
print(f"Improvement: {improvement:.2f}%")
```

```python
# ì „ëµ 2: ì•™ìƒë¸” ê²°í•©
# AutoGluonê³¼ H2Oì˜ ì˜ˆì¸¡ì„ ê²°í•©

# AutoGluon ì˜ˆì¸¡
ag_pred = ag_predictor.predict(test)

# H2O ì˜ˆì¸¡
h2o_pred = h2o_model.predict(test_h2o).as_data_frame()['predict']

# ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”
final_pred = 0.6 * ag_pred + 0.4 * h2o_pred

# ë˜ëŠ” ìŠ¤íƒœí‚¹
from sklearn.ensemble import StackingRegressor
stacking = StackingRegressor(
    estimators=[('ag', ag_predictor), ('h2o', h2o_model)],
    final_estimator=LinearRegression()
)
```

---

## ğŸ’¾ ì„¤ì¹˜ ë°©ë²•

### AutoGluon ì„¤ì¹˜

```bash
# ê¸°ë³¸ ì„¤ì¹˜ (Tabularë§Œ)
pip install autogluon.tabular

# ì „ì²´ ì„¤ì¹˜ (ëª¨ë“  ê¸°ëŠ¥)
pip install autogluon

# íŠ¹ì • ë²„ì „
pip install autogluon==1.0.0

# GPU ì§€ì› (PyTorch)
pip install autogluon
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜
git clone https://github.com/autogluon/autogluon.git
cd autogluon && ./full_install.sh
```

### H2O AutoML ì„¤ì¹˜

```bash
# ê¸°ë³¸ ì„¤ì¹˜
pip install h2o

# íŠ¹ì • ë²„ì „
pip install h2o==3.44.0.3

# Java ì„¤ì¹˜ í™•ì¸ (í•„ìˆ˜)
java -version  # Java 8 ì´ìƒ í•„ìš”

# ë©”ëª¨ë¦¬ ì„¤ì •ê³¼ í•¨ê»˜ ì´ˆê¸°í™”
python -c "import h2o; h2o.init(max_mem_size='16G')"
```

### ì˜ì¡´ì„± ìš”êµ¬ì‚¬í•­

#### AutoGluon
```
Python >= 3.8
pandas >= 1.4.1
numpy >= 1.21
scikit-learn >= 1.0
torch >= 1.12 (GPU ì‚¬ìš© ì‹œ)
```

#### H2O AutoML
```
Python >= 3.6
Java >= 8 (í•„ìˆ˜!)
requests
tabulate
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ

#### AutoGluon
- ğŸŒ [ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://auto.gluon.ai/)
- ğŸ“– [íŠœí† ë¦¬ì–¼](https://auto.gluon.ai/stable/tutorials/index.html)
- ğŸ’» [GitHub](https://github.com/autogluon/autogluon)
- ğŸ“ [API ë¬¸ì„œ](https://auto.gluon.ai/stable/api/index.html)
- ğŸ“„ [ë…¼ë¬¸](https://arxiv.org/abs/2003.06505)

#### H2O AutoML
- ğŸŒ [ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://h2o.ai/)
- ğŸ“– [ë¬¸ì„œ](http://docs.h2o.ai/)
- ğŸ’» [GitHub](https://github.com/h2oai/h2o-3)
- ğŸ“ [AutoML ê°€ì´ë“œ](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html)
- ğŸ“ [íŠœí† ë¦¬ì–¼](https://github.com/h2oai/h2o-tutorials)

---

### ì»¤ë®¤ë‹ˆí‹° ë° ì§€ì›

#### AutoGluon
- ğŸ’¬ [Slack ì»¤ë®¤ë‹ˆí‹°](https://autogluon.slack.com/)
- ğŸ› [ì´ìŠˆ íŠ¸ë˜ì»¤](https://github.com/autogluon/autogluon/issues)
- ğŸ“§ [ë©”ì¼ë§ ë¦¬ìŠ¤íŠ¸](https://groups.google.com/forum/#!forum/autogluon)

#### H2O AutoML
- ğŸ’¬ [Gitter ì±„íŒ…](https://gitter.im/h2oai/h2o-3)
- ğŸ› [JIRA](https://h2oai.atlassian.net/)
- ğŸ“§ [êµ¬ê¸€ ê·¸ë£¹](https://groups.google.com/g/h2ostream)
- ğŸ“ [ëŒ€í•™ í”„ë¡œê·¸ë¨](https://h2o.ai/university/)

---

### í•™ìŠµ ë¦¬ì†ŒìŠ¤

#### ë¸”ë¡œê·¸ ë° íŠœí† ë¦¬ì–¼
- [AutoGluon: ì‹¤ì „ ê°€ì´ë“œ (Medium)](https://medium.com/search?q=autogluon)
- [H2O.ai ë¸”ë¡œê·¸](https://www.h2o.ai/blog/)
- [Kaggle AutoML ë¹„êµ](https://www.kaggle.com/code/willkoehrsen/automl-comparison)

#### ë™ì˜ìƒ ê°•ì˜
- [AutoGluon ì‹œì‘í•˜ê¸° (YouTube)](https://www.youtube.com/results?search_query=autogluon+tutorial)
- [H2O AutoML ì™„ë²½ ê°€ì´ë“œ](https://www.youtube.com/results?search_query=h2o+automl+tutorial)

---

## ğŸ¤ ê¸°ì—¬ ë° í”¼ë“œë°±

ì´ ë¬¸ì„œëŠ” ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤. ì œì•ˆì´ë‚˜ ìˆ˜ì • ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´:

1. GitHub Issue ìƒì„±
2. Pull Request ì œì¶œ
3. ì´ë©”ì¼ë¡œ ì—°ë½

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ ë¬¸ì„œëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

---

## ğŸ“ ê²°ë¡ 

### ìµœì¢… ê¶Œì¥ ì‚¬í•­

#### ğŸ† **ëŒ€ë¶€ë¶„ì˜ ê²½ìš°: AutoGluon**
- ìµœê³  ìˆ˜ì¤€ì˜ ì •í™•ë„
- ì‚¬ìš©í•˜ê¸° ê°€ì¥ ì‰¬ì›€
- ë©€í‹°ëª¨ë‹¬ ì§€ì›
- í™œë°œí•œ ê°œë°œ ë° ì§€ì›

#### ğŸ’§ **ë‹¤ìŒì˜ ê²½ìš°: H2O AutoML**
- ë§¤ìš° í° ë°ì´í„°ì…‹ (10M+ í–‰)
- ë¹ ë¥¸ í•™ìŠµ ì†ë„ í•„ìš”
- Java í”„ë¡œë•ì…˜ í™˜ê²½
- ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥ í•„ìš”

#### ğŸ’¡ **ìµœìƒì˜ ì „ëµ**
ë‘ ë„êµ¬ë¥¼ í•¨ê»˜ ì‚¬ìš©:
1. H2Oë¡œ ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸ í™•ì¸
2. AutoGluonìœ¼ë¡œ ìµœì  ëª¨ë¸ êµ¬ì¶•
3. í•„ìš”ì‹œ ì˜ˆì¸¡ ê²°ê³¼ ì•™ìƒë¸”

---

**Happy AutoML! ğŸ‰**

*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2024ë…„ 1ì›”*
